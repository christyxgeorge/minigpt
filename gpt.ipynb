{"cells":[{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":197701,"status":"ok","timestamp":1693500434107,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"BwMOkz8ZYfyU","outputId":"7b66dc6f-f8a7-4c63-f8d1-e211ef8544b9"},"outputs":[],"source":["import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","# Reference: https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/pytorch-xla-profiling-colab.ipynb#scrollTo=Micd3xZvoA-c\n","if IN_COLAB:\n","    %pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26671,"status":"ok","timestamp":1693499161995,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"3KE2WF1SUshN","outputId":"96710b36-69a6-4f6d-cdeb-0fb9f9a5fc9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2792,"status":"ok","timestamp":1693500436893,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"HK-TEc_ITPZ8","outputId":"49131820-15da-4715-dabd-cc19c726ea89"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x10c2a4310>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","if IN_COLAB:\n","    # imports the torch_xla package\n","    import torch_xla\n","    import torch_xla.core.xla_model as xm\n","\n","torch.manual_seed(1337) ## To get repeatability!\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":808,"status":"ok","timestamp":1693499614202,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"dtoNLvDfbmmA","outputId":"01f1bf73-cab0-4d68-e5b2-7e1c58d0b5f6"},"outputs":[{"name":"stderr","output_type":"stream","text":["09:43:30 INFO:__main__: Hello\n"]}],"source":["from importlib import reload\n","import logging\n","reload(logging)\n","logging.basicConfig(format='%(asctime)s.%(msecs)03d %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n","logger = logging.getLogger(__name__)\n","logger.info(f\"{__name__}: Hello\")"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":401,"status":"ok","timestamp":1693499628074,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"Zl1J6odhTPZ_","outputId":"f46295e9-3a91-4c11-f26a-1520114179e8"},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# Hyperparameters\n","batch_size = 32\n","block_size = 8\n","n_embed = 32 ## Number of dimensions of the token embedding\n","max_iters = 3000\n","eval_interval = 300\n","eval_iters = 200\n","learning_rate = 1e-2\n","if IN_COLAB:\n","    device = 'cuda' if torch.cuda.is_available() else xm.xla_device() ### For TPU in Google collab\n","else:\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jabOTPCwTPaA"},"outputs":[],"source":["input_file = \"/content/gdrive/My Drive/data/tiny_shakespeare.txt\" # \"/content/tiny_shakespeare.txt\"\n","with open(input_file, 'r', encoding='utf-8') as f:\n","    text = f.read()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1693499635097,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"4pmWF0RqTPaA","outputId":"ebbed58c-40db-4062-ad24-28ef300c8e1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["length of text = 1115394\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You\n"]}],"source":["print(f\"length of text = {len(text)}\")\n","print(text[:100])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693499638328,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"Xa17F329TPaB","outputId":"8be530bd-0722-4b9b-e49a-72ad75d93066"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n",", ,!,$,&,',,,-,.,3,:,;,?,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z\n","Vocab Size = 65\n"]}],"source":["# Unique Characters in the text\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(','.join(chars))\n","print(f\"Vocab Size = {vocab_size}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PWJJuxjTPaC"},"outputs":[],"source":["stoi = { ch: i for i, ch in enumerate(chars)}\n","itos = { i: ch for i, ch in enumerate(chars)}\n","encode = lambda s: [ stoi[c] for c in s] # encode a string to a list of integers\n","decode = lambda l: ''.join([ itos[i] for i in l]) # decode a list of integers back to a string"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":693,"status":"ok","timestamp":1693499643326,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"SYh2jBzYTPaC","outputId":"37a6aa77-582f-4da2-e711-324c30712ce8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape: torch.Size([1115394]), Dtype: torch.int64\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"]}],"source":["# Tokenize the entire text and store into torch tensor\n","data = torch.tensor(encode(text), dtype=torch.long)\n","print(f\"Shape: {data.shape}, Dtype: {data.dtype}\")\n","print(data[:100]) ## Looks like 0 = \\n, 1 = ' '"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":467,"status":"ok","timestamp":1693499646823,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"YSxYrmqQTPaD","outputId":"c10baaa3-0285-40c2-c3c7-cba696541ad8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Split Index = 1003854, Training len = 1003854, Validation len = 111540\n"]}],"source":["# Split in train, val\n","tv_split = int(0.9*len(data))\n","train_data = data[:tv_split]\n","val_data = data[tv_split:]\n","print(f\"Split Index = {tv_split}, Training len = {len(train_data)}, Validation len = {len(val_data)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zwu66C3VTPaE"},"outputs":[],"source":["def get_batch(split, batch_size): ## Batch Size = Number of sequences being processed in parallel!\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,)) # Generate `batch_size` random offsets\n","    x = torch.stack([data[i:i+block_size] for i in ix ]) # Each sample is stacked as a row!\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix ])\n","    x, y = x.to(device), y.to(device)\n","    return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lze0kZiNTPaE"},"outputs":[],"source":["@torch.no_grad()\n","def print_estimate_loss(model, iter):\n","    xlosses = {}\n","    model.eval() ### Put in `inference` mode [Not needed in our case, no different behaviour for our model!]\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split, batch_size=batch_size)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        xlosses[split] = losses.mean()\n","        model.train()\n","    logger.info(f\"step {iter}: train loss = {xlosses['train']}, val loss = {xlosses['val']}\")\n","    return xlosses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0h0ob9RTPaF"},"outputs":[],"source":["def generate_text(num_tokens=100):\n","    ## Create the initial 'text' to generate the continuation --> Using 0 = \\n\n","    idx = torch.zeros((1,1), dtype=torch.long, device=device)\n","    tokens = m.generate(idx, num_tokens=num_tokens)\n","    print(decode(tokens[0].tolist()))"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["# Attention Head Module\n","\n","class AttentionHead(nn.Module):\n","    \"\"\"Single Attention head\"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(n_embed, head_size, bias=False)\n","        self.query = nn.Linear(n_embed, head_size, bias=False)\n","        self.value = nn.Linear(n_embed, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) ## T x T\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.key(x) # B x T x head_size (hs)\n","        q = self.query(x) # B x T x head_size (hs)\n","\n","        wei = q @ k.transpose(-2, -1) * C**-0.5 # Scaled attention\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n","        wei = F.softmax(wei, dim=-1)\n","\n","        v = self.value(x) # B x T x head_size (hs)\n","        out = wei @ v\n","        return out        \n"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    \"\"\"Multiple Attention heads running in parallel\"\"\"\n","    def __init__(self, n_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([AttentionHead(head_size) for _ in range(num_heads)])\n","\n","    def forward(self, x):\n","        return torch.cat([h(x) for h in self.heads], dim=-1) # Concatenate on the `channel` dimension"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["class FeedForward(nn.Module):\n","    \"\"\"Positional Feed Forward\"\"\"\n","    def __init__(self, n_heads, head_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embed, n_embed),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":562,"status":"ok","timestamp":1693499668503,"user":{"displayName":"Christy George","userId":"14236638916056797218"},"user_tz":-330},"id":"WX1J5EWTTPaG","outputId":"a8383b7b-b6fa-4257-c5c7-32781a56552a"},"outputs":[{"data":{"text/plain":["TransformerLanguageModel(\n","  (token_embedding_table): Embedding(65, 32)\n","  (position_embedding_table): Embedding(8, 32)\n","  (sa_head): Head(\n","    (key): Linear(in_features=32, out_features=32, bias=False)\n","    (query): Linear(in_features=32, out_features=32, bias=False)\n","    (value): Linear(in_features=32, out_features=32, bias=False)\n","  )\n","  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",")"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["# Transformer Language Model\n","class TransformerLanguageModel(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        # Each token gets the logits for the next token from the lookup table\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n","        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n","        self.sa_head = AttentionHead(n_embed//2)\n","        # 1. self.sa_heads = MultiHeadAttention(4, n_embed//4) ## 4 heads of 8-dimensional self-attention\n","        # 2. self.ffwd = FeedForward(n_embed)\n","        self.lm_head = nn.Linear(n_embed, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        # idx, targets --> B x T (batch_size x block_size)\n","        token_embedding = self.token_embedding_table(idx) # B x T x C (n_embed)\n","        position_embedding = self.position_embedding_table(torch.arange(T, device=device)) # (T x C)\n","        x = token_embedding + position_embedding ## B x T x C (position_embedding gets broadcasted for each batch)\n","        x = self.sa_head(x) # Apply a single attention head\n","        # x = self.sa_heads(x) # Apply the attention heads\n","        # x = self.ffwd(x) # B x T x C\n","        logits = self.lm_head(x) # B x T x vocab_size\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            # loss = F.cross_entropy(logits, targets) # Does not work because pytorch needs B * C * T for multi-dimensional array\n","            # So, Reshaping so that cross_entropy works\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","        return logits, loss\n","\n","    def generate(self, idx, num_tokens): ## Generate next `num_tokens` tokens, idx --> B x T\n","        for _ in range(num_tokens):\n","            # crop idx to the last block size tokens [Remove extra tokens from the beginning!]\n","            # because positional encodings are defined only upto block_size\n","            idx_cond = idx[:, -block_size:]\n","            # get the predictions/losses\n","            logits, loss = self(idx_cond) ## logits --> B x T x C\n","            # focus on last time step (only the last character)\n","            logits = logits[:, -1, :] ## --> B x C\n","            # counts = logits.exp() # counts, equivalent to N\n","            # probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n","            probs = F.softmax(logits, dim=-1) ## --> B x C\n","            # Sample from the probability distribution to get the next idx.\n","            idx_next = torch.multinomial(probs, num_samples=1) ## --> B x 1\n","            ## Question: should this not be idx_cond??\n","            idx = torch.cat((idx, idx_next), dim=1) ## --> B x T+1\n","        return idx\n","\n","\n","m = TransformerLanguageModel()\n","m.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iFjCiPRTPaG"},"outputs":[],"source":["# create an optimizer object\n","optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) # instead of torch.optim.SGD"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ehGD_A5STPaH","outputId":"0084074a-ff1f-4c8b-9aba-644555e50f85"},"outputs":[{"name":"stderr","output_type":"stream","text":["04:35:17 INFO:step 1: train loss = 4.725739479064941, val loss = 4.721153736114502\n","04:35:22 INFO:step 2: train loss = 4.72503137588501, val loss = 4.719532012939453\n","04:35:27 INFO:step 3: train loss = 4.717853546142578, val loss = 4.7250752449035645\n","04:35:32 INFO:step 4: train loss = 4.724914073944092, val loss = 4.719893932342529\n","04:35:37 INFO:step 5: train loss = 4.717930793762207, val loss = 4.724152088165283\n","04:35:42 INFO:step 6: train loss = 4.715250015258789, val loss = 4.714425563812256\n","04:35:48 INFO:step 7: train loss = 4.720458507537842, val loss = 4.715435981750488\n","04:35:54 INFO:step 8: train loss = 4.713040351867676, val loss = 4.715363025665283\n","04:36:00 INFO:step 9: train loss = 4.71272087097168, val loss = 4.711820602416992\n","04:36:07 INFO:step 10: train loss = 4.712316513061523, val loss = 4.719632148742676\n","04:36:13 INFO:step 11: train loss = 4.719141960144043, val loss = 4.715182304382324\n","04:36:19 INFO:step 12: train loss = 4.718740463256836, val loss = 4.711416721343994\n","04:36:26 INFO:step 13: train loss = 4.714872360229492, val loss = 4.70822811126709\n","04:36:33 INFO:step 14: train loss = 4.7084455490112305, val loss = 4.71446418762207\n","04:36:40 INFO:step 15: train loss = 4.704670429229736, val loss = 4.70720911026001\n","04:36:47 INFO:step 16: train loss = 4.70643424987793, val loss = 4.710766792297363\n","04:36:54 INFO:step 17: train loss = 4.701915740966797, val loss = 4.697216033935547\n","04:37:01 INFO:step 18: train loss = 4.705208778381348, val loss = 4.709928035736084\n","04:37:08 INFO:step 19: train loss = 4.701754093170166, val loss = 4.708232879638672\n","04:37:15 INFO:step 20: train loss = 4.694443225860596, val loss = 4.695245742797852\n","04:37:23 INFO:step 21: train loss = 4.696223258972168, val loss = 4.698071002960205\n","04:37:31 INFO:step 22: train loss = 4.69735050201416, val loss = 4.702807426452637\n","04:37:39 INFO:step 23: train loss = 4.693910598754883, val loss = 4.697958946228027\n","04:37:47 INFO:step 24: train loss = 4.689036846160889, val loss = 4.697938919067383\n","04:37:55 INFO:step 25: train loss = 4.691926956176758, val loss = 4.6898627281188965\n","04:38:03 INFO:step 26: train loss = 4.696292877197266, val loss = 4.688567161560059\n","04:38:12 INFO:step 27: train loss = 4.696624279022217, val loss = 4.693685531616211\n","04:38:21 INFO:step 28: train loss = 4.694997310638428, val loss = 4.686763763427734\n","04:38:30 INFO:step 29: train loss = 4.692848205566406, val loss = 4.693495273590088\n","04:38:39 INFO:step 30: train loss = 4.692241668701172, val loss = 4.685646057128906\n","04:38:49 INFO:step 31: train loss = 4.684413909912109, val loss = 4.6926589012146\n","04:38:58 INFO:step 32: train loss = 4.685116767883301, val loss = 4.685060977935791\n","04:39:08 INFO:step 33: train loss = 4.684112548828125, val loss = 4.686635494232178\n","04:39:19 INFO:step 34: train loss = 4.683040142059326, val loss = 4.687934875488281\n","04:39:30 INFO:step 35: train loss = 4.68122673034668, val loss = 4.68701171875\n","04:39:41 INFO:step 36: train loss = 4.684534549713135, val loss = 4.672389507293701\n","04:39:51 INFO:step 37: train loss = 4.684540271759033, val loss = 4.679666042327881\n","04:40:01 INFO:step 38: train loss = 4.678234100341797, val loss = 4.678635120391846\n","04:40:12 INFO:step 39: train loss = 4.680157661437988, val loss = 4.67445182800293\n","04:40:22 INFO:step 40: train loss = 4.680696487426758, val loss = 4.681201934814453\n","04:40:33 INFO:step 41: train loss = 4.6750664710998535, val loss = 4.674312591552734\n","04:40:44 INFO:step 42: train loss = 4.679248809814453, val loss = 4.675992012023926\n","04:40:55 INFO:step 43: train loss = 4.666010856628418, val loss = 4.669910907745361\n","04:41:07 INFO:step 44: train loss = 4.670851230621338, val loss = 4.674615859985352\n","04:41:18 INFO:step 45: train loss = 4.668910503387451, val loss = 4.6712517738342285\n"]}],"source":["for iter in range(max_iters): ## `max_iters` iterations\n","\n","    if not iter % eval_interval:\n","        print_estimate_loss(m, iter)\n","    xb, yb = get_batch('train', batch_size=batch_size) ## xb = B x T\n","    # print(f\"Shapes: {xb.shape} / {yb.shape}\")\n","    logits, loss = m(xb, yb)\n","    optimizer.zero_grad(set_to_none=True) ## Zero out existing gradients computed for previous step\n","    loss.backward()\n","    optimizer.step() ## change the weights based on the gradients\n","    # print(loss.item())\n","\n","print_estimate_loss(m, iter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga-iBqgvdoQq"},"outputs":[],"source":["generate_text(num_tokens=300)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["a = tensor([[1.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000],\n","        [0.3333, 0.3333, 0.3333]])\n","b = tensor([[2., 7.],\n","        [6., 4.],\n","        [6., 5.]])\n","c = tensor([[2.0000, 7.0000],\n","        [4.0000, 5.5000],\n","        [4.6667, 5.3333]])\n"]}],"source":["# Just a quick demo of tril to show how to get averages of previous rows/tokens\n","torch.manual_seed(42)   \n","a = torch.tril(torch.ones(3,3)) ## lower triangular portion (Previous tokens only!)\n","a = a / torch.sum(a, dim=1, keepdim=True) ## To average out the values of all previous tokens/rows!\n","b = torch.randint(0,10,(3,2)).float()\n","c = a @ b\n","print(f\"a = {a}\")\n","print(f\"b = {b}\")\n","print(f\"c = {c}\")\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Xbow2 allclose = True\n","Xbow3 allclose = True\n"]}],"source":["# Mathematical trick in self attention\n","# Make the tokens talk to past token -- # token # 5 talks to 0,1,2,3,4\n","\n","torch.manual_seed(1337)\n","B,T,C = 4,8,2\n","x = torch.randn(B,T,C) ### batch x time component/tokens x channels\n","\n","# we want x[b, t] = mean[i <= t] in x[b, i]\n","# Method 1: Non Matrix Method.\n","xbow = torch.zeros(B,T,C) ## bow = bag of words!\n","for b in range(B):\n","    for t in range(T):\n","        xprev = x[b,:t+1] # t, C\n","        xbow[b,t] = torch.mean(xprev, 0) # Averaging over dim=0 (time/tokens)\n","\n","# Method 2: With Tril/Averaging\n","wei = torch.tril(torch.ones(T, T)) ## T x T\n","wei = wei/wei.sum(1, keepdim=True)\n","xbow2 = wei @ x ## (T, T) x (B, T, C) ==> Because of broadcasting (T, T) => (B, T, T) ==> Output = B x T x C\n","print(f\"Xbow2 allclose = {torch.allclose(xbow, xbow2)}\")\n","\n","# Method 3: Using softmax\n","tril = torch.tril(torch.ones(T, T)) ## T x T\n","wei = torch.zeros((T, T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1) ## Same as the wei matrix in Method 2\n","xbow3 = wei @ x\n","print(f\"Xbow3 allclose = {torch.allclose(xbow, xbow3)}\")"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shapes/Variance: k = torch.Size([4, 8, 16]) // 0.3163500726222992, q = torch.Size([4, 8, 16]) // 0.33860543370246887, wei = torch.Size([4, 8, 8]) // 1.9223554134368896\n","Out shape: torch.Size([4, 8, 16]), Variance of Weights 0.04722575843334198\n"]},{"data":{"text/plain":["tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n","         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n","         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n","         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n","         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n","         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n","         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n","         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n","         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n","         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n","         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n","         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n","         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n","       grad_fn=<SoftmaxBackward0>)"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["# Self Attention\n","\n","torch.manual_seed(1337)\n","B,T,C = 4,8,32\n","x = torch.randn(B,T,C) ### batch x time component/tokens x channels\n","\n","# Single Attention Head\n","head_size = 16\n","key = nn.Linear(C, head_size, bias=False)\n","query = nn.Linear(C, head_size, bias=False)\n","value = nn.Linear(C, head_size, bias=False)\n","k = key(x) # B x T x head_size (hs)\n","q = query(x) # B x T x head_size (hs)\n","v = value(x) # B x T x head_size (hs)\n","\n","## Transpose on the last 2 dimensions! (B x T x hs) @ (B x hs x T) ==> B x T x T\n","## Scale by the attention head size to ensure that the variance is kept low.\n","## If the variance is high, then softmax will be sharpened to the max and become like a one-hot vector.\n","wei = q @ k.transpose(-2, -1) * head_size**-0.5\n","\n","print(f\"Shapes/Variance: k = {k.shape} // {k.var()}, q = {q.shape} // {q.var()}, wei = {wei.shape} // {wei.var()}\")\n","\n","tril = torch.tril(torch.ones(T, T)) ## T x T\n","# wei = torch.zeros((T, T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1) # Apply softmax to the last dimension. (first row of each wei wil be 1,0,0....)\n","# Basically, now, wei is not averaged out across previous tokens, but is data dependent....\n","\n","out = wei @ v\n","print(f\"Out shape: {out.shape}, Variance of Weights {wei.var()}\")\n","\n","wei"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
